{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "use_cuda = False\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.device(\"cuda:5\")\n",
    "    use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteinLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_particles=1, bias=True):\n",
    "        super(SteinLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_particles = n_particles\n",
    "        \n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(n_particles, in_features, out_features))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(n_particles, 1, out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(2))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = nn.PReLU()\n",
    "x = torch.Tensor([1,-2,3])\n",
    "t = torch.Tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((rr(x) - t) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.3333])\n"
     ]
    }
   ],
   "source": [
    "for name, param in rr.named_parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc = nn.Sequential(\n",
    "    SteinLinear(10, 5, 10),\n",
    "    nn.LeakyReLU(),\n",
    "    SteinLinear(5, 4, 10),\n",
    "    nn.LeakyReLU(),\n",
    "    SteinLinear(4, 1, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteinNet():\n",
    "    def __init__(self, arc, train_size):\n",
    "        '''\n",
    "        p(y|x,w) = N(y|f(x,w), alpha^-1)\n",
    "        p0(w) = N(w|0, betta^-1)\n",
    "        \n",
    "        k(w, w`) = exp^(-1/h * ||w - w`||^2)\n",
    "        '''\n",
    "        \n",
    "        ### f(x, w)\n",
    "        self.arc = arc\n",
    "        if use_cuda:\n",
    "            self.arc = self.arc.cuda()\n",
    "            \n",
    "        ### n_particles\n",
    "        self.n_particles = arc[0].n_particles\n",
    "        \n",
    "        self.train_size = train_size\n",
    "        \n",
    "        ### variances from probabilistic model\n",
    "        self.alpha = torch.tensor(1.)\n",
    "        self.betta = torch.tensor(1.)\n",
    "        if use_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "            self.betta = self.betta.cuda()\n",
    "            \n",
    "        ### factor from kernel\n",
    "        self.h = torch.tensor(1.)\n",
    "        if use_cuda:\n",
    "            self.h = self.h.cuda()\n",
    "    \n",
    "    ### SUM for all j {log p(Dj|w)}\n",
    "    ### return tensor [n_particles]\n",
    "    def calc_data_term(self, X, y):\n",
    "        two = torch.tensor(2.)\n",
    "        if use_cuda:\n",
    "            two = two.cuda()\n",
    "        \n",
    "        X = X.view(1, *X.shape).expand(self.n_particles, *X.shape)\n",
    "        y_p = self.arc(X).view(self.n_particles, X.shape[1])\n",
    "        \n",
    "        return -(torch.pow(self.alpha, two) / two) * torch.mean(torch.pow(y - y_p, two), dim=1) * self.train_size\n",
    "    \n",
    "    ### log p0(w)\n",
    "    ### return tensor [n_particles] \n",
    "    def calc_prior_term(self):\n",
    "        result = torch.zeros([self.n_particles])\n",
    "        two = torch.tensor(2.)\n",
    "        if use_cuda:\n",
    "            result = result.cuda()\n",
    "            two = two.cuda()\n",
    "            \n",
    "        for name, param in self.arc.named_parameters():\n",
    "            log_p0 = -(torch.pow(self.betta, two) / two) * torch.pow(param, two)\n",
    "            result += torch.sum(log_p0.view(param.shape[0], -1), dim=1)\n",
    "        return result\n",
    "    \n",
    "    ### k(w, w)\n",
    "    ### return tensor [n_particles, n_particles]\n",
    "    def calc_kernel_term(self):\n",
    "        one = torch.tensor(1.)\n",
    "        distances = torch.zeros([self.n_particles, self.n_particles])\n",
    "        if use_cuda:\n",
    "            one = one.cuda()\n",
    "            distances = distances.cuda()\n",
    "        \n",
    "        for name, param in self.arc.named_parameters():\n",
    "            distances += self.pairwise_distances(param.view(self.n_particles, -1), param.view(self.n_particles, -1).)\n",
    "            \n",
    "        return torch.exp(-one / self.h * distances)\n",
    "            \n",
    "    @staticmethod\n",
    "    def pairwise_distances(x, y=None):\n",
    "        '''\n",
    "        Input: x is a Nxd matrix\n",
    "               y is an optional Mxd matirx\n",
    "        Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "                if y is not given then use 'y=x'.\n",
    "        i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "        '''\n",
    "        x_norm = (x**2).sum(1).view(-1, 1)\n",
    "        if y is not None:\n",
    "            y_t = torch.transpose(y, 0, 1)\n",
    "            y_norm = (y**2).sum(1).view(1, -1)\n",
    "        else:\n",
    "            y_t = torch.transpose(x, 0, 1)\n",
    "            y_norm = x_norm.view(1, -1)\n",
    "\n",
    "        dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "        return torch.clamp(dist, 0.0, np.inf)\n",
    "    \n",
    "    def calc_objective(self, X, y):\n",
    "        prior = self.calc_prior_term\n",
    "        data = self.calc_data_term\n",
    "        kernel = self.calc_kernel_term\n",
    "        \n",
    "        log_term = prior + data\n",
    "        log_term.backward()\n",
    "        \n",
    "        kernel.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = torch.Tensor([[1, 2, 3], [2, 2, 2], [4, 3, 2]]).cuda()\n",
    "X = torch.rand([20, 10]).cuda()\n",
    "# y = torch.Tensor([1, 1, 1]).cuda()\n",
    "y = torch.rand([20]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SteinNet(arc, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9315, -3.2729, -3.8804, -3.7918, -3.3743, -3.4731, -3.4531,\n",
       "        -4.1226, -3.4281, -4.1543], device='cuda:0')"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.calc_prior_term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-250.0467, -829.3492, -305.4180,  -47.2312,  -53.1171,  -72.4147,\n",
       "         -61.3859, -127.1481, -103.7411, -913.6259], device='cuda:0')"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.calc_data_term(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  4.8717e-08,  1.1981e-07,  1.1502e-07,  4.4647e-06,\n",
       "          1.2512e-08,  1.3269e-06,  1.5255e-08,  1.8422e-08,  3.2467e-09],\n",
       "        [ 4.8717e-08,  1.0000e+00,  1.0961e-06,  1.4858e-06,  2.7744e-06,\n",
       "          2.2724e-06,  6.0164e-07,  6.8032e-08,  9.8728e-07,  5.6944e-06],\n",
       "        [ 1.1981e-07,  1.0961e-06,  1.0000e+00,  5.9653e-08,  2.0812e-07,\n",
       "          2.8557e-07,  2.0287e-08,  1.1702e-07,  6.0130e-08,  1.4912e-08],\n",
       "        [ 1.1502e-07,  1.4858e-06,  5.9653e-08,  1.0000e+00,  2.3602e-07,\n",
       "          1.0098e-05,  9.4667e-07,  2.9938e-09,  1.8713e-06,  6.7317e-07],\n",
       "        [ 4.4647e-06,  2.7744e-06,  2.0812e-07,  2.3602e-07,  1.0000e+00,\n",
       "          9.3492e-07,  7.7692e-07,  7.0353e-06,  3.2348e-07,  1.7565e-09],\n",
       "        [ 1.2512e-08,  2.2724e-06,  2.8557e-07,  1.0098e-05,  9.3492e-07,\n",
       "          1.0000e+00,  4.3401e-06,  6.5919e-08,  1.6981e-06,  7.9088e-07],\n",
       "        [ 1.3269e-06,  6.0164e-07,  2.0287e-08,  9.4667e-07,  7.7692e-07,\n",
       "          4.3401e-06,  1.0000e+00,  2.4388e-07,  7.8790e-06,  1.2781e-06],\n",
       "        [ 1.5255e-08,  6.8032e-08,  1.1702e-07,  2.9938e-09,  7.0353e-06,\n",
       "          6.5919e-08,  2.4388e-07,  1.0000e+00,  1.2802e-06,  2.4223e-08],\n",
       "        [ 1.8422e-08,  9.8728e-07,  6.0130e-08,  1.8713e-06,  3.2348e-07,\n",
       "          1.6981e-06,  7.8790e-06,  1.2802e-06,  1.0000e+00,  1.0611e-07],\n",
       "        [ 3.2467e-09,  5.6944e-06,  1.4912e-08,  6.7317e-07,  1.7565e-09,\n",
       "          7.9088e-07,  1.2781e-06,  2.4223e-08,  1.0611e-07,  1.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.calc_kernel_term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
